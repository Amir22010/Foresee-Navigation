commit 89ea3e41bfc7f5fe0fb1fc609e2fcde4d4caa32f
Author: Josh Hejna <josh.hejna@gmail.com>
Date:   Thu Aug 2 15:28:14 2018 -0700

    TEMP

diff --git b/ros_workspace/src/deep_segmentation/src/network.py a/ros_workspace/src/deep_segmentation/src/network.py
index a947f2a..cd52478 100755
--- b/ros_workspace/src/deep_segmentation/src/network.py
+++ a/ros_workspace/src/deep_segmentation/src/network.py
@@ -1,6 +1,7 @@
+#!/usr/bin/env python
 import tensorflow as tf
 slim = tf.contrib.slim
-from resnet import resnet_v2, resnet_utils
+import resnet_v2, resnet_utils
 
 # ImageNet mean statistics
 _R_MEAN = 123.68
@@ -9,19 +10,12 @@ _B_MEAN = 103.94
 
 @slim.add_arg_scope
 def atrous_spatial_pyramid_pooling(net, scope, depth=256, reuse=None):
-    """
-    ASPP consists of (a) one 1×1 convolution and three 3×3 convolutions with rates = (6, 12, 18) when output stride = 16
-    (all with 256 filters and batch normalization), and (b) the image-level features as described in https://arxiv.org/abs/1706.05587
-    :param net: tensor of shape [BATCH_SIZE, WIDTH, HEIGHT, DEPTH]
-    :param scope: scope name of the aspp layer
-    :return: network layer with aspp applyed to it.
-    """
 
     with tf.variable_scope(scope, reuse=reuse):
         feature_map_size = tf.shape(net)
 
         # apply global average pooling
-        image_level_features = tf.reduce_mean(net, [1, 2], name='image_level_global_pool', keepdims=True)
+        image_level_features = tf.reduce_mean(net, [1, 2], name='image_level_global_pool', keep_dims=True)
         image_level_features = slim.conv2d(image_level_features, depth, [1, 1], scope="image_level_conv_1x1",
                                            activation_fn=None)
         image_level_features = tf.image.resize_bilinear(image_level_features, (feature_map_size[1], feature_map_size[2]))
@@ -65,7 +59,7 @@ def deeplab_v3(inputs, args, is_training, reuse):
 
             net = atrous_spatial_pyramid_pooling(net, "ASPP_layer", depth=256, reuse=reuse)
 
-            net = slim.conv2d(net, args.number_of_classes, [1, 1], activation_fn=None,
+            net = slim.conv2d(net, 5, [1, 1], activation_fn=None,
                               normalizer_fn=None, scope='logits')
 
             size = tf.shape(inputs)[1:3]
diff --git b/ros_workspace/src/deep_segmentation/src/resnet_utils.py a/ros_workspace/src/deep_segmentation/src/resnet_utils.py
index 59f6ad4..8d657bf 100755
--- b/ros_workspace/src/deep_segmentation/src/resnet_utils.py
+++ a/ros_workspace/src/deep_segmentation/src/resnet_utils.py
@@ -1,3 +1,4 @@
+#!/usr/bin/env python
 # Copyright 2016 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
diff --git b/ros_workspace/src/deep_segmentation/src/resnet_v2.py a/ros_workspace/src/deep_segmentation/src/resnet_v2.py
index 1ab1835..c8b1871 100755
--- b/ros_workspace/src/deep_segmentation/src/resnet_v2.py
+++ a/ros_workspace/src/deep_segmentation/src/resnet_v2.py
@@ -1,3 +1,4 @@
+#!/usr/bin/env python
 # Copyright 2016 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
@@ -52,7 +53,7 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-from resnet import resnet_utils
+import resnet_utils
 
 slim = tf.contrib.slim
 resnet_arg_scope = resnet_utils.resnet_arg_scope
diff --git b/ros_workspace/src/deep_segmentation/src/train.py a/ros_workspace/src/deep_segmentation/src/train.py
index 278fc46..34e3a92 100755
--- b/ros_workspace/src/deep_segmentation/src/train.py
+++ a/ros_workspace/src/deep_segmentation/src/train.py
@@ -6,10 +6,10 @@ slim = tf.contrib.slim
 import os
 import json
 import network
-from preprocessing.read_data import download_resnet_checkpoint_if_necessary, tf_record_parser, \
+from read_data import download_resnet_checkpoint_if_necessary, tf_record_parser, \
     rescale_image_and_annotation_by_factor, scale_image_with_crop_padding, \
     random_flip_image_and_annotation, distort_randomly_image_color
-from preprocessing import training
+import training
 
 # 0=background
 # 1=aeroplane
@@ -39,7 +39,7 @@ parser = argparse.ArgumentParser()
 envarg = parser.add_argument_group('Training params')
 envarg.add_argument("--batch_norm_epsilon", type=float, default=1e-5, help="batch norm epsilon argument for batch normalization")
 envarg.add_argument('--batch_norm_decay', type=float, default=0.9997, help='batch norm decay argument for batch normalization.')
-envarg.add_argument("--number_of_classes", type=int, default=21, help="Number of classes to be predicted.")
+envarg.add_argument("--number_of_classes", type=int, default=5, help="Number of classes to be predicted.")
 envarg.add_argument("--l2_regularizer", type=float, default=0.0001, help="l2 regularizer parameter.")
 envarg.add_argument('--starting_learning_rate', type=float, default=0.00001, help="initial learning rate.")
 envarg.add_argument("--multi_grid", type=list, default=[1,2,4], help="Spatial Pyramid Pooling rates")
@@ -166,7 +166,7 @@ with tf.Session() as sess:
     try:
         restorer.restore(sess, "./resnet/checkpoints/" + args.resnet_model + ".ckpt")
         print("Model checkpoits for " + args.resnet_model + " restored!")
-    except FileNotFoundError:
+    except:
         print("ResNet checkpoints not found. Please download " + args.resnet_model + " model checkpoints from: https://github.com/tensorflow/models/tree/master/research/slim")
 
     # The `Iterator.string_handle()` method returns a tensor that can be evaluated
